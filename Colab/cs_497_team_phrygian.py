# -*- coding: utf-8 -*-
"""CS-497-Team-Phrygian.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HqnpWgofEE4GRry4obFq9_cu9qGFD9K3
"""

from   sklearn.linear_model import LogisticRegression
import numpy                as np
import pandas               as pd


# Using scikitlearn we will use logistical regression model

# Load in data from csv file that was downloaded from kaggle
# https://www.kaggle.com/washingtonpost/police-shootings
min_columns = ['manner_of_death', 'armed', 'age', 'gender', 'race', 'city', 'state', 'signs_of_mental_illness', 'threat_level','flee', 'body_camera']
removeList  = ['manner_of_death', 'armed', 'gender', 'race', 'city', 'state', 'signs_of_mental_illness', 'threat_level','flee', 'body_camera']
dataFrame   = pd.read_csv("database.csv", names=min_columns, skiprows=1)

print(dataFrame.shape)

# There is text data in our CSV so we will have to use pandas dummy variables to address this issue and merge the dummies with the dataframe
dummiesList = [dataFrame]
dummiesList.append(pd.get_dummies(dataFrame.manner_of_death))
dummiesList.append(pd.get_dummies(dataFrame.armed))
dummiesList.append(pd.get_dummies(dataFrame.gender))
dummiesList.append(pd.get_dummies(dataFrame.race))
dummiesList.append(pd.get_dummies(dataFrame.city))
dummiesList.append(pd.get_dummies(dataFrame.state))
dummiesList.append(pd.get_dummies(dataFrame.signs_of_mental_illness))
dummiesList.append(pd.get_dummies(dataFrame.threat_level))
dummiesList.append(pd.get_dummies(dataFrame.flee))
dummiesList.append(pd.get_dummies(dataFrame.body_camera))

# Now we can merge the Lists
encodedDF = pd.concat(dummiesList, axis='columns')
encodedDF = encodedDF.drop(removeList, axis='columns')
encodedDF.age = encodedDF[['age']].fillna(0)


# The data is clean
features = encodedDF.columns[1:]
print(features)

X = encodedDF[features]
Y = encodedDF.age

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics
from numpy import array
model = LogisticRegression(max_iter=10000)


#Split the data!
Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.15,random_state=0)
#Train with the data!
model.fit(Xtrain,Ytrain)
#Test the Model
predictions = model.predict(Xtest)

#TBH Cleaning the data and making sure the shapes of the matricies were in line
#one anothe had to be one of the hardest parts of this whole thing. The
#actual training took like not even 5 min

# What this thing does in a nutshell is it will take in the following parameters
# ['manner_of_death', 'armed', 'gender', 'race', 'city', 'state', 'signs_of_mental_illness', 'threat_level','flee', 'body_camera']
# And it will try and determine your age


print("The Accuracy of our predictions is: ",metrics.accuracy_score(Ytest, predictions))

#This cell should only be ran if we train the model on new data
#No need to run this unless the program can't see the pickled 
#object

import pickle

file = open('/content/model.pkl', 'wb')
pickle.dump(model, file)
file.close()

#Testing the Data with our own inputs

#Create a dictionary and set each key to a column and instantiate each value 
#to be 0 to start out with
testDat = {}
for feature in features:
	testDat[feature] = 0

#Assign each slot that we want to have our test person have with a 1
testDat['shot'] = 1
testDat['vehicle'] = 1
testDat['M'] = 1
testDat['W'] = 1
testDat['Los Angeles'] = 1
testDat['CA'] = 1
testDat['False'] = 1
testDat['attack'] = 1
testDat['Not fleeing'] = 1
testDat['False'] =1

#Iterate through all the keys and put their values in an array 
modelInput = []
for key in testDat:
  modelInput.append(testDat[key])
#This next step is here because there were 8 columns that were taken away from 
#and we have to put them back
for i in range(8):
  modelInput.append(0)

print("The out put is a prediction of a White Male that was shot in")
print("Los Angeles, California who attacked the police and did not flee")
print("The prediction is....   " + str(model.predict([modelInput])))